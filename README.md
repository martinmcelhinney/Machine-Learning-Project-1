# Machine-Learning-Project-1
This is the final assignment completed using Jupyter Notebook for the Machine Learning Module for my Higher Diploma in Data Analytics. I received a grade of 86% for this project.  

**Part A:**
I have been hired by Internatonal insurance plc to work on a machine learning project for the enterprise with the objective of developing an optimised machine learning model capable of tackling a prediction task for a problem domain.
The problem domain identified is the following:

How do we predict the probability of a car insurance policyholder making a claim on their policy based on the data provided on the policyholder and their vehicle?

The approach taken involved:

Data Cleaning and Exploritory Analysis

Feature Extraction/Feature Engineering - Encoding and Scaling the Data.

Feature Selection / Dimensionality Reduction - Recursive Feature Elimination (RFE) and Principal Component Analysis (PCA)

Choice of modelling techniques for my analysis from Logistical Regression, K-Nearest Neighbours (KNN), Random Forest.

Model Evaluation and Comparison using the Hyperparameter Optimised Accuracy Score.  


**Part B:**
I carried out an analysis on the Enron Email Dataset. The dataset contains approximately 500,000 emails generated by employees of the Enron Corporation. It was obtained by the Federal Energy Regulatory Commission (FERC) during the course of their investigation into the Enron Collapse.

My objective with this analysis was to apply a k-means unsupervised machine learning clustering model to the dataset to identify distinct clusters of email messages based on their content. This was achieved as follows:

Data Cleaning and Exploritory Analysis

Pre-processed the data for K-Means clustering using vectorisation.

Reduced the dimensionality of the data using the TruncatedSVD function.

Determined the optimal value of K using the inflection point method.

Applied the K-means model and visualised the clusters using a scatter plot.

**Part C:**
I performed a text analysis of the “IMDB Dataset of 50k Movie Reviews” dataset. The dataset contains approximately 50,000 movie reviews from the Internet Movie Database (IMDB) along with whether the sentiment of the review was positive or negative. My objective with this analysis is to build a text analysis model to predict the sentiment towards a movie based on the text content of a review. I achieved this through the application of Bag of Words and TFIDF models.

This was achieved as follows:

Data Cleaning and Exploritory Analysis.

Tokenisation of the data.

Stemmed the text to reduce the words in the text to their root.

Normalised the Train and Test text.

Consttructed the Bag-of-Words Model to serve as a foundation for the more advanced Term Frequency - Inverse Document Frequency (TFIDF) techniques.

Constructed a TF-IDF model 

Applied a Logistic Regression to provide interpretable coeffcints for each word which indicate the strength and direction of the relationship between specific words and how they relate to the target classes.



